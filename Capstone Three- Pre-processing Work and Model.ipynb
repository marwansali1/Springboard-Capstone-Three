{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a974ff8",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d403c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "px.defaults.width = 1200\n",
    "px.defaults.height = 800\n",
    "# plotly.io Settings for both plotly.graph_objects and plotly.express\n",
    "pio.templates.default = \"plotly_white\" # \"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"\n",
    "\"\"\"\n",
    "pio.kaleido.scope.default_format = 'svg'\n",
    "pio.kaleido.scope.default_scale = 1\n",
    "\"\"\"\n",
    "\n",
    "# Data Preprocessing - Standardization, Encoding, Imputation\n",
    "from sklearn.preprocessing import StandardScaler # Standardization\n",
    "from sklearn.preprocessing import Normalizer # Normalization\n",
    "from sklearn.preprocessing import OneHotEncoder # One-hot Encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding\n",
    "from category_encoders import MEstimateEncoder # Target Encoding\n",
    "from sklearn.preprocessing import PolynomialFeatures # Create Polynomial Features\n",
    "from sklearn.impute import SimpleImputer # Imputation\n",
    "\n",
    "# Exploratory Data Analysis - Feature Engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modeling - ML Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Modeling - Algorithms\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "#from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# ML - Evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# ML - Tuning\n",
    "import optuna\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Settings\n",
    "# Settings for Seaborn\n",
    "sns.set_theme(context='notebook', style='ticks', palette=\"bwr_r\", font_scale=0.7, rc={\"figure.dpi\":240, 'savefig.dpi':240})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d91ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "kaggle_project = 'seattle'\n",
    "# Import dataset from local directory './data' or from Kaggle\n",
    "data_dir = ('./data/201601' if os.path.exists('data') else f'/kaggle/input/{kaggle_project}')\n",
    "\n",
    "# print all files in data_dir\n",
    "for dirname, _, filenames in os.walk(data_dir):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Import three datasets\n",
    "reviews = pd.read_csv('reviews.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "listings = pd.read_csv('listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06fe15df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_listings_kfold():\n",
    "    # Mark the train dataset with kfold = 5\n",
    "    listings = pd.read_csv('listings.csv')\n",
    "    if os.path.exists(f'{data_dir}/listings_kfold.csv'):\n",
    "        os.remove(f'{data_dir}/listings_kfold.csv')\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X=listings)):\n",
    "        listings.loc[valid_idx, \"kfold\"] = fold\n",
    "\n",
    "    listings.to_csv(f'listings_kfold.csv', index=False)\n",
    "\n",
    "generate_listings_kfold()\n",
    "listings = pd.read_csv(f'listings_kfold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8f8327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>953595</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3308979</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7421966</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278830</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  kfold\n",
       "0   241032    0.0\n",
       "1   953595    4.0\n",
       "2  3308979    2.0\n",
       "3  7421966    3.0\n",
       "4   278830    4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After assigning kfold\n",
    "# If error, run the above function then re-load listings_kfold.csv\n",
    "listings.loc[:, ['id', 'kfold']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa48e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sheet id and base url\n",
    "sheet_id = \"1M_qah-ym6O8vDcSmoKAP-lbZRPHUey83R_DJaW3LXfs\"\n",
    "base_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet=\"\n",
    "\n",
    "# Load metadata for three datasets\n",
    "listings_metadata = pd.read_csv(base_url+\"listings\")\n",
    "calendar_metadata = pd.read_csv(base_url+\"calendar\")\n",
    "reviews_metadata = pd.read_csv(base_url+\"reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c229f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETL_pipeline:\n",
    "    def __init__(self, data_frame):\n",
    "        self.df = data_frame\n",
    "    \n",
    "    # Data type transformation\n",
    "    def _transformation(self, data_frame):\n",
    "        df = data_frame\n",
    "        # Convert dollar columns from object to float\n",
    "        # Remove '$' and ','\n",
    "        dollar_cols = ['price', 'weekly_price', 'monthly_price', 'extra_people', 'security_deposit', 'cleaning_fee']\n",
    "        for dollar_col in dollar_cols:\n",
    "            df[dollar_col] = df[dollar_col].replace('[\\$,]', '', regex=True).astype(float)\n",
    "        # Convert dollar columns from object to float\n",
    "        # Remove '%'\n",
    "        percent_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "        for percent_col in percent_cols:\n",
    "            df[percent_col] = df[percent_col].replace('%', '', regex=True).astype(float)\n",
    "\n",
    "        # Replace the following values in property_type to Unique space due to small sample size\n",
    "        unique_space = [\"Barn\",\n",
    "        \"Boat\",\n",
    "        \"Bus\",\n",
    "        \"Camper/RV\",\n",
    "        \"Treehouse\",\n",
    "        \"Campsite\",\n",
    "        \"Castle\",\n",
    "        \"Cave\",\n",
    "        \"Dome House\",\n",
    "        \"Earth house\",\n",
    "        \"Farm stay\",\n",
    "        \"Holiday park\",\n",
    "        \"Houseboat\",\n",
    "        \"Hut\",\n",
    "        \"Igloo\",\n",
    "        \"Island\",\n",
    "        \"Lighthouse\",\n",
    "        \"Plane\",\n",
    "        \"Ranch\",\n",
    "        \"Religious building\",\n",
    "        \"Shepherd’s hut\",\n",
    "        \"Shipping container\",\n",
    "        \"Tent\",\n",
    "        \"Tiny house\",\n",
    "        \"Tipi\",\n",
    "        \"Tower\",\n",
    "        \"Train\",\n",
    "        \"Windmill\",\n",
    "        \"Yurt\",\n",
    "        \"Riad\",\n",
    "        \"Pension\",\n",
    "        \"Dorm\",\n",
    "        \"Chalet\"]            \n",
    "        df.property_type = df.property_type.replace(unique_space, \"Unique space\", regex=True)\n",
    "\n",
    "        # Convert 't', 'f' to 1, 0\n",
    "        tf_cols = ['host_is_superhost', 'instant_bookable', 'require_guest_profile_picture', 'require_guest_phone_verification']\n",
    "        for tf_col in tf_cols:\n",
    "            df[tf_col] = df[tf_col].replace('f', 0, regex=True)\n",
    "            df[tf_col] = df[tf_col].replace('t', 1, regex=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Parse listings\n",
    "    def parse_listings(self):\n",
    "        \"\"\"Parse listings.\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        df = self._transformation(df)\n",
    "        return df\n",
    "    \n",
    "    def parse_reviews(self):\n",
    "        \"\"\"Parse reviews.\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        df.date = pd.to_datetime(df.date)\n",
    "        return df\n",
    "    \n",
    "    # Parse calendar\n",
    "    def parse_calender(self):\n",
    "        \"\"\"Paser calendar.\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        # Convert date from object to datetime\n",
    "        df.date = pd.to_datetime(df.date)\n",
    "        # Convert price from object to float\n",
    "        # Convert '$' and ',' to ''\n",
    "        df.price = df.price.replace('[\\$,]', '', regex=True).astype(float)\n",
    "        \n",
    "        # Convert 't', 'f' to 1, 0\n",
    "        df['available'] = df['available'].replace('f', 0, regex=True)\n",
    "        df['available'] = df['available'].replace('t', 1, regex=True)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc66e696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>$85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>953595</td>\n",
       "      <td>$150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3308979</td>\n",
       "      <td>$975.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7421966</td>\n",
       "      <td>$100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278830</td>\n",
       "      <td>$450.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    price\n",
       "0   241032   $85.00\n",
       "1   953595  $150.00\n",
       "2  3308979  $975.00\n",
       "3  7421966  $100.00\n",
       "4   278830  $450.00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. Before parsing\n",
    "listings.loc[:4, ['id', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee2f9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = ETL_pipeline(listings).parse_listings()\n",
    "reviews = ETL_pipeline(reviews).parse_reviews()\n",
    "calendar = ETL_pipeline(calendar).parse_calender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb497cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>953595</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3308979</td>\n",
       "      <td>975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7421966</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278830</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  price\n",
       "0   241032   85.0\n",
       "1   953595  150.0\n",
       "2  3308979  975.0\n",
       "3  7421966  100.0\n",
       "4   278830  450.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. After parsing\n",
    "listings.loc[:4, ['id', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b8530cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDA_demand:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def reviews_rate_vs_unavailability(self, period=30):\n",
    "        \"\"\"Calculate the booked listing from file calendar.\n",
    "\n",
    "        Args:\n",
    "            period (int): Positive integer. Default is 30.\n",
    "\n",
    "        Returns:\n",
    "            Pandas DataFrame.\n",
    "        \"\"\"\n",
    "        assert (0 < period <= 365) & isinstance(period, int), \"period must be an integer and greater than 0\"\n",
    "        self.period = period\n",
    "        \n",
    "        #\n",
    "        # Calculate review rate & unavailability\n",
    "        #\n",
    "\n",
    "        # reviews Rate: review / days\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            listing_id, \n",
    "            COUNT(listing_id) / DATEDIFF(20160104+1, MIN(date)) AS reviews_per_day\n",
    "        FROM reviews\n",
    "        GROUP BY listing_id\n",
    "        \"\"\"\n",
    "        # Extract the first reviews date for each listing\n",
    "        func = lambda df: pd.Series({'first_day': df.date.min()})\n",
    "        df_reviews_per_day = pd.DataFrame(reviews.groupby('listing_id').apply(func))\n",
    "        # Define last scraped date\n",
    "        last_scraped = listings.last_scraped.unique()[0]\n",
    "        last_scraped = pd.Timestamp(last_scraped)\n",
    "        df_reviews_per_day['last_day'] = last_scraped + pd.DateOffset(days=1)\n",
    "        # Calculate the datediff\n",
    "        df_reviews_per_day['datediff'] = df_reviews_per_day.last_day - df_reviews_per_day.first_day\n",
    "        df_reviews_per_day['datediff'] = df_reviews_per_day['datediff'].dt.days\n",
    "        # Calculate the reviews Rate\n",
    "        df_reviews_per_day['reviews_per_day'] = reviews.groupby('listing_id').size() / df_reviews_per_day['datediff']\n",
    "\n",
    "        \"\"\"\n",
    "        SELECT listing_id, SUM(IF(available = 0, 1, 0))\n",
    "        FROM calendar\n",
    "        WHERE DATEDIFF(date, 20160104) <= period\n",
    "        GROUP BY listing_id\n",
    "        \"\"\"\n",
    "        last_day = last_scraped + pd.DateOffset(days=period-1)\n",
    "        filter = calendar.date <= (last_day)\n",
    "        func = lambda df: pd.Series({f'unavailability_{period}_unscaled': sum(df.available == 0)}) # Scaling available to day scale\n",
    "        df_unavailability = pd.DataFrame(calendar[filter].groupby('listing_id').apply(func))\n",
    "        df_unavailability[f'unavailability_{period}'] = df_unavailability[f'unavailability_{period}_unscaled'] / period\n",
    "        #df_unavailability['first_day'] = last_scraped\n",
    "        #df_unavailability['last_day'] = last_day\n",
    "        self.df_unavailability = df_unavailability\n",
    "        \n",
    "        # Join two tables\n",
    "        df_unavailability_reviews = df_unavailability.join(df_reviews_per_day, how='left')\n",
    "        df_unavailability_reviews.reviews_per_day.fillna(value=0, inplace=True)\n",
    "        #df_unavailability_reviews.loc[:, [f'unavailability_{period}_unscaled', f'unavailability_{period}', 'reviews_per_day']]\n",
    "        \n",
    "        # Find outliers (unavailable rather than booked)\n",
    "        # Extrat quantiles\n",
    "        reviews_rate_25 = df_unavailability_reviews.reviews_per_day.quantile(q=0.25, interpolation='higher')\n",
    "        unavailability_75 = df_unavailability_reviews[f'unavailability_{period}'].quantile(q=0.75, interpolation='higher')\n",
    "        # Low reviews rate: 0.010376\n",
    "        filter1 = df_unavailability_reviews.reviews_per_day < reviews_rate_25\n",
    "        # High unavailability: 0.660274\n",
    "        filter2 = df_unavailability_reviews[f'unavailability_{period}'] > unavailability_75\n",
    "\n",
    "        outliers = df_unavailability_reviews[filter1 & filter2]\n",
    "        df_unavailability_reviews['demand'] = df_unavailability_reviews[f'unavailability_{period}_unscaled']\n",
    "        df_unavailability_reviews.loc[outliers.index, 'demand'] = period - df_unavailability_reviews.loc[outliers.index, 'demand']\n",
    "        \n",
    "        self.outliers = outliers\n",
    "        self.df_unavailability_reviews = df_unavailability_reviews\n",
    "        \n",
    "        return self.df_unavailability_reviews\n",
    "    \n",
    "    def plot(self, outliers=True):\n",
    "        \"\"\"Display plot or describe the relationship between reviews per day and unavailabilities to filter the outliers of demand.\n",
    "        \n",
    "        Args:\n",
    "            outlier (bool): Display outliers or not. Default is True\n",
    "            \n",
    "        Returns:\n",
    "            Plotly instance\n",
    "        \"\"\"\n",
    "        period = self.period\n",
    "        \n",
    "        if outliers is True:\n",
    "            idx = self.outliers.index\n",
    "            df = self.df_unavailability_reviews.loc[idx, :]\n",
    "        else:\n",
    "            idx = self.df_unavailability_reviews.index.drop(self.outliers.index)\n",
    "            df = self.df_unavailability_reviews.loc[idx, :]\n",
    "\n",
    "        assert df.shape[0] > 0, \"No records\"\n",
    "\n",
    "        fig = px.line(df, \n",
    "                      x=df.index, \n",
    "                      y=[f'unavailability_{period}', 'reviews_per_day'],\n",
    "                      color_discrete_sequence=['rgb(71, 92, 118, 0.9)', 'rgb(250, 211, 102, 0.9)']\n",
    "                     )\n",
    "        fig.update_layout(title=f'Unavailability per day vs. reviews per day<br>Outliers', xaxis_title='index', yaxis_title='Rate')\n",
    "\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a89a8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML_pipeline:\n",
    "    \"\"\"ML Pipeline for listings.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_frame, features, target, days=365):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            data_frame (Pandas DataFrame): listings.\n",
    "            features (list): The Machine Learning features.\n",
    "            target (str): price\n",
    "            days (int): The days after 2016-01-04 for calculating demand.\n",
    "        \"\"\"\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\") # ignore target encoding warnings\n",
    "        \n",
    "        # Get demand\n",
    "        demand = EDA_demand().reviews_rate_vs_unavailability(days)\n",
    "        # The index will change to id\n",
    "        data_frame = data_frame.set_index('id').join(demand['demand'], how='inner')\n",
    "        \n",
    "        features.append(target)\n",
    "        data_frame = data_frame[features]\n",
    "        \n",
    "        # Encode amenities\n",
    "        data_frame = self._encode_amentities(data_frame)\n",
    "        data_frame.pop('amenities')\n",
    "        \n",
    "        self.data_frame = data_frame\n",
    "        \n",
    "    # encode amentities\n",
    "    def _encode_amentities(self, data_frame):\n",
    "        # Replace amenities from {}\" to ''\n",
    "        data_frame.amenities.replace('[{}\"]', '', regex=True, inplace=True)\n",
    "        # Split amenities with ,\n",
    "        amenities = data_frame.amenities.str.split(',', expand=True)\n",
    "        \n",
    "        \"\"\"All amenities\n",
    "        '24-Hour Check-in',\n",
    "        'Air Conditioning',\n",
    "        'Breakfast',\n",
    "        'Buzzer/Wireless Intercom',\n",
    "        'Cable TV',\n",
    "        'Carbon Monoxide Detector',\n",
    "        'Cat(s)',\n",
    "        'Dog(s)',\n",
    "        'Doorman',\n",
    "        'Dryer',\n",
    "        'Elevator in Building',\n",
    "        'Essentials',\n",
    "        'Family/Kid Friendly',\n",
    "        'Fire Extinguisher',\n",
    "        'First Aid Kit',\n",
    "        'Free Parking on Premises',\n",
    "        'Gym',\n",
    "        'Hair Dryer',\n",
    "        'Hangers',\n",
    "        'Heating',\n",
    "        'Hot Tub',\n",
    "        'Indoor Fireplace',\n",
    "        'Internet',\n",
    "        'Iron',\n",
    "        'Kitchen',\n",
    "        'Laptop Friendly Workspace',\n",
    "        'Lock on Bedroom Door',\n",
    "        'Other pet(s)',\n",
    "        'Pets Allowed',\n",
    "        'Pets live on this property',\n",
    "        'Pool',\n",
    "        'Safety Card',\n",
    "        'Shampoo',\n",
    "        'Smoke Detector',\n",
    "        'Smoking Allowed',\n",
    "        'Suitable for Events',\n",
    "        'TV',\n",
    "        'Washer',\n",
    "        'Washer / Dryer',\n",
    "        'Wheelchair Accessible',\n",
    "        'Wireless Internet'\n",
    "        \"\"\"\n",
    "\n",
    "        # For each col, extract the unique amenities\n",
    "        amenities_uniques = []\n",
    "        for col in amenities.columns:\n",
    "            amenities_uniques += list(amenities[col].unique())\n",
    "\n",
    "        # Remove the duplicate values\n",
    "        amenities_uniques = set(amenities_uniques)\n",
    "        amenities_uniques.remove('')\n",
    "        amenities_uniques.remove(None)\n",
    "        # Only two rows have Washer / Dryer, and they both have washer and dryer\n",
    "        amenities_uniques.remove('Washer / Dryer')\n",
    "        # When 'Pets live on this property' is True, one or more from 'Cat(s)', 'Dog(s)', 'Other pet(s)' will appear\n",
    "\n",
    "        # Encoding amenities\n",
    "        amenities_enc = pd.DataFrame()\n",
    "        for amenity in amenities_uniques:\n",
    "            amenities_enc[amenity] = data_frame.amenities.str.contains(amenity, regex=False)\n",
    "\n",
    "        # Rename the columns with prefix amenity_\n",
    "        amenities_enc.columns = [f\"amenity_{col}\" for col in amenities_enc.columns]\n",
    "        \n",
    "        # Concat encoded amenities and data_frame\n",
    "        data_frame = pd.concat([data_frame, amenities_enc], axis=1)\n",
    "\n",
    "        return data_frame\n",
    "\n",
    "    def _imputation(self, X_train, X_valid, y_train, y_valid):\n",
    "        X_train, X_valid, y_train, y_valid = X_train.copy(), X_valid.copy(), y_train.copy(), y_valid.copy()\n",
    "        \n",
    "        # Zero imputation\n",
    "        # Reason:\n",
    "        zero_imp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "        zero_features = ['reviews_per_month', 'host_response_rate', 'host_is_superhost', 'security_deposit', 'cleaning_fee']\n",
    "        X_train_zero_imp = pd.DataFrame(zero_imp.fit_transform(X_train[zero_features]))\n",
    "        X_valid_zero_imp = pd.DataFrame(zero_imp.transform(X_valid[zero_features]))\n",
    "        X_train_zero_imp.columns = zero_features\n",
    "        X_valid_zero_imp.columns = zero_features\n",
    "        X_train_zero_imp.index = X_train.index\n",
    "        X_valid_zero_imp.index = X_valid.index\n",
    "        X_train_zero_imp = X_train_zero_imp.astype(float)\n",
    "        X_valid_zero_imp = X_valid_zero_imp.astype(float)\n",
    "        \n",
    "        # Mean imputation\n",
    "        # Reason:\n",
    "        mean_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        mean_features = ['host_acceptance_rate', 'review_scores_accuracy', 'review_scores_checkin', \n",
    "                         'review_scores_value', 'review_scores_location', 'review_scores_cleanliness', \n",
    "                         'review_scores_communication', 'review_scores_rating']\n",
    "        X_train_mean_imp = pd.DataFrame(mean_imp.fit_transform(X_train[mean_features]))\n",
    "        X_valid_mean_imp = pd.DataFrame(mean_imp.transform(X_valid[mean_features]))\n",
    "        X_train_mean_imp.columns = mean_features\n",
    "        X_valid_mean_imp.columns = mean_features\n",
    "        X_train_mean_imp.index = X_train.index\n",
    "        X_valid_mean_imp.index = X_valid.index\n",
    "        X_train_mean_imp = X_train_mean_imp.astype(float)\n",
    "        X_valid_mean_imp = X_valid_mean_imp.astype(float)\n",
    "        \n",
    "        # Mode imputation\n",
    "        # Reason: \n",
    "        mode_imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "        mode_features = ['bathrooms', 'bedrooms', 'beds', 'property_type']\n",
    "        X_train_mode_imp = pd.DataFrame(mode_imp.fit_transform(X_train[mode_features]))        \n",
    "        X_valid_mode_imp = pd.DataFrame(mode_imp.transform(X_valid[mode_features]))\n",
    "        X_train_mode_imp.columns = mode_features\n",
    "        X_valid_mode_imp.columns = mode_features\n",
    "        X_train_mode_imp.index = X_train.index\n",
    "        X_valid_mode_imp.index = X_valid.index\n",
    "        X_train_mode_imp[['bathrooms', 'bedrooms', 'beds']] = X_train_mode_imp[['bathrooms', 'bedrooms', 'beds']].astype(int)\n",
    "        X_valid_mode_imp[['bathrooms', 'bedrooms', 'beds']] = X_valid_mode_imp[['bathrooms', 'bedrooms', 'beds']].astype(int)\n",
    "        \n",
    "        # Replace the unimputated columns\n",
    "        for feature in zero_features:\n",
    "            X_train[feature] = X_train_zero_imp[feature]\n",
    "            X_valid[feature] = X_valid_zero_imp[feature]\n",
    "        \n",
    "        for feature in mean_features:\n",
    "            X_train[feature] = X_train_mean_imp[feature]\n",
    "            X_valid[feature] = X_valid_mean_imp[feature]\n",
    "\n",
    "        for feature in mode_features:\n",
    "            X_train[feature] = X_train_mode_imp[feature]\n",
    "            X_valid[feature] = X_valid_mode_imp[feature]\n",
    "        \n",
    "        return X_train, X_valid, y_train, y_valid\n",
    "    \n",
    "    def _one_hot_encoding(self, X_train, X_valid, y_train, y_valid):\n",
    "        X_train, X_valid, y_train, y_valid = X_train.copy(), X_valid.copy(), y_train.copy(), y_valid.copy()\n",
    "        \n",
    "        oe_enc_features = ['cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification', \n",
    "                               'neighbourhood_group_cleansed', 'property_type', 'instant_bookable', 'room_type', 'bed_type']\n",
    "        \n",
    "        oe = OrdinalEncoder()\n",
    "        X_train[oe_enc_features] = oe.fit_transform(X_train[oe_enc_features])\n",
    "        X_valid[oe_enc_features] = oe.transform(X_valid[oe_enc_features])\n",
    "    \n",
    "        return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "    def _target_encoding(self, X_train, X_valid, y_train, y_valid):\n",
    "        X_train, X_valid, y_train, y_valid = X_train.copy(), X_valid.copy(), y_train.copy(), y_valid.copy()\n",
    "        \n",
    "        target_enc_features = ['cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification', \n",
    "                               'neighbourhood_group_cleansed', 'property_type', 'instant_bookable', 'room_type', 'bed_type']\n",
    "        \n",
    "        # Create the encoder instance. Choose m to control noise.\n",
    "        target_enc = MEstimateEncoder(cols=target_enc_features, m=5.0)\n",
    "        X_train = target_enc.fit_transform(X_train, y_train)\n",
    "        X_valid = target_enc.transform(X_valid)\n",
    "        \n",
    "        return X_train, X_valid, y_train, y_valid\n",
    "    \n",
    "    def getData(self, kfold, target_encoding=True):\n",
    "        data_frame = self.data_frame.copy()\n",
    "        \n",
    "        # Split train and valid\n",
    "        X_train = data_frame[data_frame.kfold != kfold]\n",
    "        X_valid = data_frame[data_frame.kfold == kfold]\n",
    "        y_train = X_train.pop('price')\n",
    "        y_valid = X_valid.pop('price')\n",
    "        \n",
    "        # Imputation\n",
    "        X_train, X_valid, y_train, y_valid = self._imputation(X_train, X_valid, y_train, y_valid)\n",
    "        \n",
    "        # Target Encoding\n",
    "        if target_encoding:\n",
    "            X_train, X_valid, y_train, y_valid = self._target_encoding(X_train, X_valid, y_train, y_valid)\n",
    "        else:\n",
    "            X_train, X_valid, y_train, y_valid = self._one_hot_encoding(X_train, X_valid, y_train, y_valid)\n",
    "        \n",
    "        return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39b008aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>neighbourhood_group_cleansed</th>\n",
       "      <th>property_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>Queen Anne</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>953595</td>\n",
       "      <td>Queen Anne</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>{TV,Internet,\"Wireless Internet\",Kitchen,\"Free...</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3308979</td>\n",
       "      <td>Queen Anne</td>\n",
       "      <td>House</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
       "      <td>975.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id neighbourhood_group_cleansed property_type  \\\n",
       "0   241032                   Queen Anne     Apartment   \n",
       "1   953595                   Queen Anne     Apartment   \n",
       "2  3308979                   Queen Anne         House   \n",
       "\n",
       "                                           amenities  price  \n",
       "0  {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...   85.0  \n",
       "1  {TV,Internet,\"Wireless Internet\",Kitchen,\"Free...  150.0  \n",
       "2  {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...  975.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. Before ML pipeline\n",
    "listings.loc[:2, ['id', 'neighbourhood_group_cleansed', 'property_type', 'amenities', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06d7733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. After ML pipeline\n",
    "features = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "            'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "            'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "            'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "            'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "            'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "            'require_guest_phone_verification', 'amenities', 'demand', 'kfold']\n",
    "\n",
    "ml_pipeline = ML_pipeline(data_frame=listings, features=features, target='price')\n",
    "X_train, X_valid, y_train, y_valid = ml_pipeline.getData(kfold=0, target_encoding=True) # perform target encoding\n",
    "X = pd.concat([X_train, X_valid], axis=0)\n",
    "y = pd.concat([y_train, y_valid])\n",
    "X['price'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "178bdd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group_cleansed</th>\n",
       "      <th>property_type</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241032</th>\n",
       "      <td>151.102994</td>\n",
       "      <td>123.397576</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953595</th>\n",
       "      <td>151.102994</td>\n",
       "      <td>123.397576</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308979</th>\n",
       "      <td>151.102994</td>\n",
       "      <td>132.880445</td>\n",
       "      <td>975.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         neighbourhood_group_cleansed  property_type  price\n",
       "241032                     151.102994     123.397576   85.0\n",
       "953595                     151.102994     123.397576  150.0\n",
       "3308979                    151.102994     132.880445  975.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[[241032, 953595, 3308979], ['neighbourhood_group_cleansed', 'property_type', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19a00a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amenity_Elevator in Building</th>\n",
       "      <th>amenity_Essentials</th>\n",
       "      <th>amenity_Lock on Bedroom Door</th>\n",
       "      <th>amenity_Safety Card</th>\n",
       "      <th>amenity_Hot Tub</th>\n",
       "      <th>amenity_Suitable for Events</th>\n",
       "      <th>amenity_Dog(s)</th>\n",
       "      <th>amenity_Wheelchair Accessible</th>\n",
       "      <th>amenity_Pets live on this property</th>\n",
       "      <th>amenity_Fire Extinguisher</th>\n",
       "      <th>...</th>\n",
       "      <th>amenity_Breakfast</th>\n",
       "      <th>amenity_Gym</th>\n",
       "      <th>amenity_Hair Dryer</th>\n",
       "      <th>amenity_Smoking Allowed</th>\n",
       "      <th>amenity_Wireless Internet</th>\n",
       "      <th>amenity_TV</th>\n",
       "      <th>amenity_Smoke Detector</th>\n",
       "      <th>amenity_First Aid Kit</th>\n",
       "      <th>amenity_Hangers</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241032</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953595</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308979</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>975.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amenity_Elevator in Building  amenity_Essentials  \\\n",
       "241032                          False               False   \n",
       "953595                          False                True   \n",
       "3308979                         False                True   \n",
       "\n",
       "         amenity_Lock on Bedroom Door  amenity_Safety Card  amenity_Hot Tub  \\\n",
       "241032                          False                False            False   \n",
       "953595                          False                 True            False   \n",
       "3308979                         False                False             True   \n",
       "\n",
       "         amenity_Suitable for Events  amenity_Dog(s)  \\\n",
       "241032                         False           False   \n",
       "953595                         False           False   \n",
       "3308979                        False            True   \n",
       "\n",
       "         amenity_Wheelchair Accessible  amenity_Pets live on this property  \\\n",
       "241032                           False                               False   \n",
       "953595                           False                               False   \n",
       "3308979                          False                                True   \n",
       "\n",
       "         amenity_Fire Extinguisher  ...  amenity_Breakfast  amenity_Gym  \\\n",
       "241032                       False  ...              False        False   \n",
       "953595                        True  ...              False        False   \n",
       "3308979                      False  ...              False        False   \n",
       "\n",
       "         amenity_Hair Dryer  amenity_Smoking Allowed  \\\n",
       "241032                False                    False   \n",
       "953595                False                    False   \n",
       "3308979               False                    False   \n",
       "\n",
       "         amenity_Wireless Internet  amenity_TV  amenity_Smoke Detector  \\\n",
       "241032                        True        True                   False   \n",
       "953595                        True        True                    True   \n",
       "3308979                       True        True                    True   \n",
       "\n",
       "         amenity_First Aid Kit  amenity_Hangers  price  \n",
       "241032                   False            False   85.0  \n",
       "953595                    True            False  150.0  \n",
       "3308979                  False            False  975.0  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. After ML pipeline\n",
    "X.loc[[241032, 953595, 3308979], 'amenity_Elevator in Building':]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f198fb9",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "The models in this project are [XGBoost](https://xgboost.readthedocs.io/en/latest/) and [LightGBM](https://lightgbm.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96c951",
   "metadata": {},
   "source": [
    "#### ML Baseline\n",
    "The baseline can provide an insight into the performance of different data preprocessing strategies, such as encoding methods.\n",
    "Here, I chose target encoding. First, it had a better performance than ordinal encoding. Second, we already knew the categorical data have potential levels for a different price.\n",
    "e.g. different roomt_type has different price histogram.\n",
    "\n",
    "Features marked as ML1 were defined by Airbnb for Machine Learning models.\n",
    "Then, as you can see, ML1 + ML2 is better than ML1, which means we found more features that were useful for Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8831db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1, kfold: 0. RMSE: 56.64589093002433\n",
      "ML1, kfold: 1. RMSE: 62.44468185143068\n",
      "ML1, kfold: 2. RMSE: 60.40781093438012\n",
      "ML1, kfold: 3. RMSE: 63.666798642194124\n",
      "ML1, kfold: 4. RMSE: 52.226979216000906\n",
      "ML1. Average RMSE: 59.07843231480604\n",
      "\n",
      "ML1 + ML2, kfold: 0. RMSE: 52.92355341945994\n",
      "ML1 + ML2, kfold: 1. RMSE: 65.04777557551235\n",
      "ML1 + ML2, kfold: 2. RMSE: 58.69704656344895\n",
      "ML1 + ML2, kfold: 3. RMSE: 55.149794448218394\n",
      "ML1 + ML2, kfold: 4. RMSE: 49.509631025616585\n",
      "ML1 + ML2. Average RMSE: 56.26556020645124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "One Hot Encoding\n",
    "ML1, kfold: 0. RMSE: 56.481995126446456\n",
    "ML1, kfold: 1. RMSE: 66.83960978199953\n",
    "ML1, kfold: 2. RMSE: 61.957734603524976\n",
    "ML1, kfold: 3. RMSE: 62.69133725976135\n",
    "ML1, kfold: 4. RMSE: 55.715497896362415\n",
    "ML1. Average RMSE: 60.73723493361895\n",
    "\n",
    "ML1 + ML2, kfold: 0. RMSE: 52.568454955844246\n",
    "ML1 + ML2, kfold: 1. RMSE: 63.234791588163155\n",
    "ML1 + ML2, kfold: 2. RMSE: 58.68112865265134\n",
    "ML1 + ML2, kfold: 3. RMSE: 60.09474908722824\n",
    "ML1 + ML2, kfold: 4. RMSE: 47.693034296085685\n",
    "ML1 + ML2. Average RMSE: 56.45443171599453\n",
    "\n",
    "Target Encoding\n",
    "ML1, kfold: 0. RMSE: 56.64589093002433\n",
    "ML1, kfold: 1. RMSE: 62.44468185143068\n",
    "ML1, kfold: 2. RMSE: 60.40781093438012\n",
    "ML1, kfold: 3. RMSE: 63.666798642194124\n",
    "ML1, kfold: 4. RMSE: 52.226979216000906\n",
    "ML1. Average RMSE: 59.07843231480604\n",
    "\n",
    "ML1 + ML2, kfold: 0. RMSE: 52.92355341945994\n",
    "ML1 + ML2, kfold: 1. RMSE: 65.04777557551235\n",
    "ML1 + ML2, kfold: 2. RMSE: 58.69704656344895\n",
    "ML1 + ML2, kfold: 3. RMSE: 55.149794448218394\n",
    "ML1 + ML2, kfold: 4. RMSE: 49.509631025616585\n",
    "ML1 + ML2. Average RMSE: 56.26556020645124\n",
    "\"\"\"\n",
    "\n",
    "def baseline(target_encoding=True):\n",
    "    #import warnings\n",
    "    #warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    features = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "                'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "                'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "                'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "                'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "                'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "                'require_guest_phone_verification', 'amenities', 'demand', 'kfold']\n",
    "\n",
    "    ml_pipeline = ML_pipeline(data_frame=listings, features=features, target='price')\n",
    "    \n",
    "    amenities = ['amenity_Washer', 'amenity_Air Conditioning', 'amenity_TV',\n",
    "                 'amenity_Kitchen', 'amenity_Wheelchair Accessible',\n",
    "                 'amenity_Free Parking on Premises', 'amenity_Doorman',\n",
    "                 'amenity_Cable TV', 'amenity_Smoke Detector',\n",
    "                 'amenity_Pets live on this property', 'amenity_Internet',\n",
    "                 'amenity_Hangers', 'amenity_Family/Kid Friendly',\n",
    "                 'amenity_First Aid Kit', 'amenity_Indoor Fireplace', 'amenity_Gym',\n",
    "                 'amenity_Suitable for Events', 'amenity_Breakfast', 'amenity_Cat(s)',\n",
    "                 'amenity_Lock on Bedroom Door', 'amenity_Smoking Allowed',\n",
    "                 'amenity_Dog(s)', 'amenity_Shampoo', 'amenity_Hair Dryer',\n",
    "                 'amenity_Carbon Monoxide Detector', 'amenity_Wireless Internet',\n",
    "                 'amenity_Hot Tub', 'amenity_Safety Card',\n",
    "                 'amenity_Buzzer/Wireless Intercom', 'amenity_Pool',\n",
    "                 'amenity_Elevator in Building', 'amenity_Pets Allowed',\n",
    "                 'amenity_Fire Extinguisher', 'amenity_Other pet(s)',\n",
    "                 'amenity_Laptop Friendly Workspace', 'amenity_Essentials',\n",
    "                 'amenity_Iron', 'amenity_Dryer', 'amenity_24-Hour Check-in',\n",
    "                 'amenity_Heating']\n",
    "    \n",
    "    # Define sheet id and base url\n",
    "    sheet_id = \"1M_qah-ym6O8vDcSmoKAP-lbZRPHUey83R_DJaW3LXfs\"\n",
    "    base_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet=\"\n",
    "\n",
    "    # Load metadata for three datasets\n",
    "    listings_metadata = pd.read_csv(base_url+\"listings\")\n",
    "    calendar_metadata = pd.read_csv(base_url+\"calendar\")\n",
    "    reviews_metadata = pd.read_csv(base_url+\"reviews\")\n",
    "    \n",
    "    # ML1\n",
    "    ml1 = listings_metadata[listings_metadata.ML == 1].Label.to_list()\n",
    "    useless_features = ['availability_30', 'availability_60', 'availability_90', 'availability_365', 'first_review', 'last_review', 'amenities']\n",
    "    for useless_feature in useless_features:\n",
    "        ml1.remove(useless_feature)\n",
    "    ml1.append('demand')\n",
    "    ml1 += amenities\n",
    "    \n",
    "    AVG_RMSE = []\n",
    "    for kfold in range(5):\n",
    "        X_train, X_test, y_train, y_test = ml_pipeline.getData(kfold=kfold, target_encoding=target_encoding)\n",
    "        model = XGBRegressor(random_state=kfold, n_jobs=-1)\n",
    "        model.fit(X_train[ml1], y_train)\n",
    "        test_preds = model.predict(X_test[ml1])\n",
    "        RMSE = mean_squared_error(y_test, test_preds, squared=False)\n",
    "        print(f\"ML1, kfold: {kfold}. RMSE: {RMSE}\")\n",
    "        AVG_RMSE.append(RMSE)\n",
    "    print(f\"ML1. Average RMSE: {np.mean(AVG_RMSE)}\\n\")\n",
    "        \n",
    "    # ML1 + ML2\n",
    "    ml1 = listings_metadata[listings_metadata.ML == 1].Label.to_list()\n",
    "    useless_features = ['availability_30', 'availability_60', 'availability_90', 'availability_365', 'first_review', 'last_review', 'amenities']\n",
    "    for useless_feature in useless_features:\n",
    "        ml1.remove(useless_feature)\n",
    "    ml2 = listings_metadata[listings_metadata.ML == 2].Label.to_list()\n",
    "    ml2.append('demand')\n",
    "    ml2 = ml1 + ml2 + amenities\n",
    "    \n",
    "    AVG_RMSE = []\n",
    "    for kfold in range(5):\n",
    "        X_train, X_test, y_train, y_test = ml_pipeline.getData(kfold=kfold, target_encoding=target_encoding)\n",
    "        model = XGBRegressor(random_state=kfold, n_jobs=-1)\n",
    "        model.fit(X_train[ml2], y_train)\n",
    "        test_preds = model.predict(X_test[ml2])\n",
    "        RMSE = mean_squared_error(y_test, test_preds, squared=False)\n",
    "        print(f\"ML1 + ML2, kfold: {kfold}. RMSE: {RMSE}\")\n",
    "        AVG_RMSE.append(RMSE)\n",
    "    print(f\"ML1 + ML2. Average RMSE: {np.mean(AVG_RMSE)}\\n\")\n",
    "\n",
    "baseline(target_encoding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba4ec7",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "- The Hyperparameter tuning platform I used is [Optuna](https://optuna.org/). We implemented a logger to write the tuning results in the local log file. After all tunings are finished, the program will sent an email to my mailbox with the best hyperparameters.\n",
    "\n",
    "- To enable this feature, go to configure your gmail first.\n",
    "- P.S: If your computer does not support GPU accleration, uncomment code For CPU and comment code For GPU.\n",
    "\n",
    "- If you want to train your model, DO NOT RUN the following code in this notebook. Instead, make another notebook for model tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15909bef",
   "metadata": {},
   "source": [
    "#### Define Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7dbfcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Define logger\n",
    "logger = logging.getLogger('ML')\n",
    "\n",
    "# Set level for logger\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Define the handler and formatter for file logging\n",
    "log_file = 'ML'\n",
    "fileHandler = logging.FileHandler(f'{log_file}.log') # Define FileHandler\n",
    "fileHandler.setLevel(logging.INFO) # Set level\n",
    "fileFormatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') # Define formatter\n",
    "fileHandler.setFormatter(fileFormatter) # Set formatter\n",
    "logger.addHandler(fileHandler) # Add handler to logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2e728",
   "metadata": {},
   "source": [
    "#### Define Features for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "754ecfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sheet id and base url\n",
    "sheet_id = \"1M_qah-ym6O8vDcSmoKAP-lbZRPHUey83R_DJaW3LXfs\"\n",
    "base_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet=\"\n",
    "\n",
    "# Load metadata for three datasets\n",
    "listings_metadata = pd.read_csv(base_url+\"listings\")\n",
    "calendar_metadata = pd.read_csv(base_url+\"calendar\")\n",
    "reviews_metadata = pd.read_csv(base_url+\"reviews\")\n",
    "\n",
    "amenities = ['amenity_Washer', 'amenity_Air Conditioning', 'amenity_TV',\n",
    "             'amenity_Kitchen', 'amenity_Wheelchair Accessible',\n",
    "             'amenity_Free Parking on Premises', 'amenity_Doorman',\n",
    "             'amenity_Cable TV', 'amenity_Smoke Detector',\n",
    "             'amenity_Pets live on this property', 'amenity_Internet',\n",
    "             'amenity_Hangers', 'amenity_Family/Kid Friendly',\n",
    "             'amenity_First Aid Kit', 'amenity_Indoor Fireplace', 'amenity_Gym',\n",
    "             'amenity_Suitable for Events', 'amenity_Breakfast', 'amenity_Cat(s)',\n",
    "             'amenity_Lock on Bedroom Door', 'amenity_Smoking Allowed',\n",
    "             'amenity_Dog(s)', 'amenity_Shampoo', 'amenity_Hair Dryer',\n",
    "             'amenity_Carbon Monoxide Detector', 'amenity_Wireless Internet',\n",
    "             'amenity_Hot Tub', 'amenity_Safety Card',\n",
    "             'amenity_Buzzer/Wireless Intercom', 'amenity_Pool',\n",
    "             'amenity_Elevator in Building', 'amenity_Pets Allowed',\n",
    "             'amenity_Fire Extinguisher', 'amenity_Other pet(s)',\n",
    "             'amenity_Laptop Friendly Workspace', 'amenity_Essentials',\n",
    "             'amenity_Iron', 'amenity_Dryer', 'amenity_24-Hour Check-in',\n",
    "             'amenity_Heating']\n",
    "    \n",
    "# ML1 + ML2\n",
    "ml1 = listings_metadata[listings_metadata.ML == 1].Label.to_list()\n",
    "useless_features = ['availability_30', 'availability_60', 'availability_90', 'availability_365', 'first_review', 'last_review', 'amenities']\n",
    "for useless_feature in useless_features:\n",
    "    ml1.remove(useless_feature)\n",
    "ml2 = listings_metadata[listings_metadata.ML == 2].Label.to_list()\n",
    "ml2.append('demand')\n",
    "ml2 = ml1 + ml2 + amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18250d07",
   "metadata": {},
   "source": [
    "#### Tuning Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c309f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence Optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6316966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of trails\n",
    "n_trials = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89a3f5",
   "metadata": {},
   "source": [
    "#### Model Tuning: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "483435ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Modeling tuning with Target encoding.\n",
    "    \"\"\"\n",
    "    features = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "                'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "                'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "                'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "                'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "                'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "                'require_guest_phone_verification', 'amenities', 'demand', 'kfold']\n",
    "\n",
    "    ml_pipeline = ML_pipeline(data_frame=listings, features=features, target='price')\n",
    "    \n",
    "    RMSE_AVG = []\n",
    "    for kfold in range(5):\n",
    "        X_train, X_valid, y_train, y_valid = ml_pipeline.getData(kfold=kfold, target_encoding=True)\n",
    "        X_train, X_valid = X_train[ml2], X_valid[ml2]\n",
    "        \n",
    "        # Hyperparameters for XGBoost\n",
    "        xgb_params = {\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "            'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0),\n",
    "            'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0),\n",
    "            'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "            'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.3, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 10000),\n",
    "            'max_depth': trial.suggest_int(\"max_depth\", 1, 7),\n",
    "            'random_state': trial.suggest_categorical('random_state', [0, 42, 2021]),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 300)\n",
    "        }\n",
    "\n",
    "        # For GPU\n",
    "        model = XGBRegressor(\n",
    "                tree_method='gpu_hist',\n",
    "                gpu_id=0,\n",
    "                predictor='gpu_predictor',\n",
    "                **xgb_params)\n",
    "        \n",
    "        '''\n",
    "        # For CPU\n",
    "        model = XGBRegressor(**xgb_params)\n",
    "        '''\n",
    "        \n",
    "        model.fit(\n",
    "            X_train, y_train, \n",
    "            early_stopping_rounds=300,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            verbose=5000\n",
    "        )\n",
    "        \n",
    "        valid_preds = model.predict(X_valid)\n",
    "        RMSE = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        RMSE_AVG.append(RMSE)\n",
    "    \n",
    "    return np.mean(RMSE_AVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abe8c878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%time\\nstudy = optuna.create_study(direction=\\'minimize\\', study_name=f\\'XGBoost {n_trials} trails\\')\\nstudy.optimize(objective, n_trials=n_trials, show_progress_bar=False) # set n_triasl\\n\\nlogger.info(f\"Study name: {study.study_name}\")\\nlogger.info(f\"Best value: {study.best_value}\")\\nlogger.info(f\"Best paras: {study.best_params}\")\\nlogger.info(\"Mission Complete! --------------\")\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "study = optuna.create_study(direction='minimize', study_name=f'XGBoost {n_trials} trails')\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=False) # set n_triasl\n",
    "\n",
    "logger.info(f\"Study name: {study.study_name}\")\n",
    "logger.info(f\"Best value: {study.best_value}\")\n",
    "logger.info(f\"Best paras: {study.best_params}\")\n",
    "logger.info(\"Mission Complete! --------------\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76c313",
   "metadata": {},
   "source": [
    "#### Model Tuning: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "667aee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Modeling tuning with Target encoding.\n",
    "    \"\"\"\n",
    "    features = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "                'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "                'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "                'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "                'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "                'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "                'require_guest_phone_verification', 'amenities', 'demand', 'kfold']\n",
    "\n",
    "    ml_pipeline = ML_pipeline(data_frame=listings, features=features, target='price')\n",
    "    \n",
    "    RMSE_AVG = []\n",
    "    for kfold in range(5):\n",
    "        X_train, X_valid, y_train, y_valid = ml_pipeline.getData(kfold=kfold, target_encoding=True)\n",
    "        X_train, X_valid = X_train[ml2], X_valid[ml2]\n",
    "        \n",
    "        # Hyperparameters for LightGBM\n",
    "        lgb_params = {\n",
    "            'random_state': trial.suggest_categorical('random_state', [0, 42, 2021]),\n",
    "            'num_iterations': trial.suggest_int('num_iterations', 100, 10000),\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.3, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 7),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 100, 2000),\n",
    "            'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "            'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.01, 0.99),\n",
    "            'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.01, 0.99),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        }\n",
    "\n",
    "        # For GPU\n",
    "        model = LGBMRegressor(\n",
    "                    device='gpu',\n",
    "                    gpu_platform_id=0,\n",
    "                    gpu_device_id=0,\n",
    "                    n_jobs=-1,\n",
    "                    metric='rmse',\n",
    "                    **lgb_params\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        # For CPU\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        '''\n",
    "        \n",
    "        model.fit(\n",
    "            X_train, y_train, \n",
    "            early_stopping_rounds=300,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            verbose=5000\n",
    "        )\n",
    "        \n",
    "        valid_preds = model.predict(X_valid)\n",
    "        RMSE = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        RMSE_AVG.append(RMSE)\n",
    "    \n",
    "    return np.mean(RMSE_AVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b92775b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%time\\nstudy = optuna.create_study(direction=\\'minimize\\', study_name=f\\'LGBoost {n_trials} trails\\')\\nstudy.optimize(objective, n_trials=n_trials, show_progress_bar=False) # set n_triasl\\n\\nlogger.info(f\"Study name: {study.study_name}\")\\nlogger.info(f\"Best value: {study.best_value}\")\\nlogger.info(f\"Best paras: {study.best_params}\")\\nlogger.info(\"Mission Complete! --------------\")\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "study = optuna.create_study(direction='minimize', study_name=f'LGBoost {n_trials} trails')\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=False) # set n_triasl\n",
    "\n",
    "logger.info(f\"Study name: {study.study_name}\")\n",
    "logger.info(f\"Best value: {study.best_value}\")\n",
    "logger.info(f\"Best paras: {study.best_params}\")\n",
    "logger.info(\"Mission Complete! --------------\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906182a2",
   "metadata": {},
   "source": [
    "#### Gmail Configuration\n",
    "[How to Send Emails with Gmail using Python](https://stackabuse.com/how-to-send-emails-with-gmail-using-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a61e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmail(YOUR_GMAIL, YOUR_APP_PASSWORD, SEND_TO):\n",
    "    \"\"\"Send the ML tuning result to one or more email addresses.\n",
    "    \n",
    "    Args:\n",
    "        YOUR_GMAIL (str): Your gmail address.\n",
    "        YOUR_APP_PASSWORD (str): Your APP Password for gmail. \n",
    "        SEND_TO (str or list): The target emails.\n",
    "    \"\"\"\n",
    "    gmail_user = YOUR_GMAIL\n",
    "    gmail_password = YOUR_APP_PASSWORD # Google App Password\n",
    "\n",
    "    import smtplib\n",
    "    from email.message import EmailMessage\n",
    "\n",
    "    msg = EmailMessage()\n",
    "    msg[\"From\"] = YOUR_GMAIL\n",
    "    msg[\"Subject\"] = \"Seattle Airbnb ML Tuning\"\n",
    "    msg[\"To\"] = SEND_TO\n",
    "    msg.set_content(f\"\"\"\\\n",
    "    {n_trials} Trials are done.\n",
    "    Mission Complete!\"\"\")\n",
    "    with open('ML.log', 'rb') as f:\n",
    "        content = f.read()\n",
    "        msg.add_attachment(content, maintype='application', subtype='log', filename='ML.log')\n",
    "\n",
    "    server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "    server.login(gmail_user, gmail_password)\n",
    "    server.send_message(msg)\n",
    "    server.close()\n",
    "#gmail(YOUR_GMAIL, YOUR_APP_PASSWORD, SEND_TO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6797549",
   "metadata": {},
   "source": [
    "#### Model Blending\n",
    "\n",
    "Reference: [Ensemble Learning: Stacking, Blending & Voting](https://towardsdatascience.com/ensemble-learning-stacking-blending-voting-b37737c4f483)\n",
    "\n",
    "After hyperparameter tuning, we have a set of beter hyperparameters for XGBoost and LightGBM. Then I performed a model blending for a better ML performance.\n",
    "\n",
    "My 200 Trails ( 200×5 in total) hyperparameters:\n",
    "\n",
    "- ###### XGBoost\n",
    "\n",
    "{'lambda': 0.029949323233957558, 'alpha': 0.47821306780284645, 'reg_lambda': 0.03007272817610808, 'reg_alpha': 5.7650942972599255e-05, 'colsample_bytree': 0.32733907049678806, 'subsample': 0.9397958925107069, 'learning_rate': 0.016087339011505105, 'n_estimators': 4117, 'max_depth': 6, 'random_state': 42, 'min_child_weight': 5}\n",
    "\n",
    "- ###### LightGBM\n",
    "\n",
    "{'random_state': 42, 'num_iterations': 5549, 'learning_rate': 0.07313607774375752, 'max_depth': 5, 'num_leaves': 75, 'min_data_in_leaf': 100, 'lambda_l1': 1.3379869858112054e-06, 'lambda_l2': 0.00025091437242776726, 'feature_fraction': 0.5910800704597817, 'bagging_fraction': 0.9553891294481797, 'bagging_freq': 6, 'min_child_samples': 23}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d044fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Blending:\n",
    "    def __init__(self, data_frame, features_etl, features_ml):\n",
    "        data_frame = data_frame.copy()\n",
    "        self.ml_pipeline = ML_pipeline(data_frame=data_frame, features=features_etl, target='price')\n",
    "        self.features_ml = features_ml\n",
    "    \n",
    "    def _xgboost_reg(self, xgb_params):\n",
    "        \"\"\"\n",
    "        # For GPU\n",
    "        model = XGBRegressor(\n",
    "                    tree_method='gpu_hist',\n",
    "                    gpu_id=0,\n",
    "                    predictor='gpu_predictor',\n",
    "                    n_jobs=-1,\n",
    "                    **xgb_params\n",
    "                )\n",
    "        \"\"\"\n",
    "        \n",
    "        # For CPU\n",
    "        model = XGBRegressor(**xgb_params)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _lightgbm_reg(self, lgb_params):\n",
    "        \"\"\"\n",
    "        # For GPU\n",
    "        model = LGBMRegressor(\n",
    "                    device='gpu',\n",
    "                    gpu_platform_id=0,\n",
    "                    gpu_device_id=0,\n",
    "                    n_jobs=-1,\n",
    "                    metric='rmse',\n",
    "                    **lgb_params\n",
    "                )\n",
    "        \"\"\"\n",
    "        \n",
    "        # For CPUT\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def blending(self, model: str, params: dict):\n",
    "        '''Model blending. Generate 5 predictions according to 5 folds.\n",
    "        \n",
    "        Args:\n",
    "            model: One of xgboost or lightgbm.\n",
    "            params: Hyperparameters for XGBoost or LightGBM.\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        assert model in ['xgboost', 'lightgbm'], \"ValueError: model must be one of ['xgboost', 'lightgbm']!\"\n",
    "        \n",
    "        final_valid_predictions = {}\n",
    "        scores = []\n",
    "        \n",
    "        for fold in range(5):\n",
    "            X_train, X_valid, y_train, y_valid = self.ml_pipeline.getData(kfold=fold, target_encoding=True)\n",
    "            X_train, X_valid = X_train[self.features_ml], X_valid[self.features_ml] # Add many amenities\n",
    "            # Get X_valid_ids\n",
    "            X_valid_ids = list(X_valid.index)\n",
    "            \n",
    "            print(f\"Training ...\")\n",
    "            # Define model\n",
    "            if model == 'xgboost':\n",
    "                reg = self._xgboost_reg(params)\n",
    "            elif model == 'lightgbm':\n",
    "                reg = self._lightgbm_reg(params)\n",
    "\n",
    "            # Modeling - Training\n",
    "            reg.fit(\n",
    "                X_train, y_train, \n",
    "                early_stopping_rounds=300,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # Modeling - Inference\n",
    "            valid_preds = reg.predict(X_valid)\n",
    "            \n",
    "            final_valid_predictions.update(dict(zip(X_valid_ids, valid_preds))) # loop 5 times with different valid id\n",
    "\n",
    "            rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "            scores.append(rmse)\n",
    "            print(f'Fold: {fold}, RMSE: {rmse}')\n",
    "            \n",
    "        # Export results\n",
    "        if not os.path.exists('output'):\n",
    "            os.mkdir('output')\n",
    "        final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "        final_valid_predictions.columns = [\"id\", f\"{model}_pred\"]\n",
    "        final_valid_predictions.to_csv(f\"output/{model}_valid_pred.csv\", index=False)\n",
    "\n",
    "        print('-----------------------------------------------------------------')\n",
    "        print(f'Average RMSE: {np.mean(scores)}, STD of RMSE: {np.std(scores)}') \n",
    "        \n",
    "    def predict(self, models: list):\n",
    "        df_valids = pd.read_csv(f'output/{models[0]}_valid_pred.csv')\n",
    "        models.remove(models[0])\n",
    "        for model in models:\n",
    "            df = pd.read_csv(f'output/{model}_valid_pred.csv')\n",
    "            df_valids = df_valids.set_index('id').join(df.set_index('id'), how='inner')\n",
    "        \n",
    "        # Calculate the average predictions\n",
    "        df_valids['mean_valids'] = df_valids.mean(axis=1)\n",
    "        # Join listings price to df_valids\n",
    "        df_valids['price'] = listings.set_index('id')['price']\n",
    "        \n",
    "        # Use the average predictions to validate the target\n",
    "        return mean_squared_error(df_valids.price, df_valids['mean_valids'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eefcce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_etl = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "            'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "            'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "            'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "            'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "            'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "            'require_guest_phone_verification', 'amenities', 'demand', 'kfold']\n",
    "\n",
    "features_ml = ml2\n",
    "\n",
    "xgb_params = {'lambda': 0.029949323233957558, 'alpha': 0.47821306780284645, 'reg_lambda': 0.03007272817610808, \n",
    "              'reg_alpha': 5.7650942972599255e-05, 'colsample_bytree': 0.32733907049678806, 'subsample': 0.9397958925107069, \n",
    "              'learning_rate': 0.016087339011505105, 'n_estimators': 4117, 'max_depth': 6, 'random_state': 42, 'min_child_weight': 5}\n",
    "\n",
    "lgb_params = {'random_state': 42, 'num_iterations': 5549, 'learning_rate': 0.07313607774375752, 'max_depth': 5, 'num_leaves': 75, \n",
    "             'min_data_in_leaf': 100, 'lambda_l1': 1.3379869858112054e-06, 'lambda_l2': 0.00025091437242776726, \n",
    "             'feature_fraction': 0.5910800704597817, 'bagging_fraction': 0.9553891294481797, 'bagging_freq': 6, 'min_child_samples': 23}\n",
    "\n",
    "model_blending = Model_Blending(listings, features_etl, features_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa46728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Fold: 0, RMSE: 47.754405543201784\n",
      "Training ...\n",
      "Fold: 1, RMSE: 61.119641697842376\n",
      "Training ...\n",
      "Fold: 2, RMSE: 54.63793671561086\n",
      "Training ...\n",
      "Fold: 3, RMSE: 56.08790855238088\n",
      "Training ...\n",
      "Fold: 4, RMSE: 45.39565863542171\n",
      "-----------------------------------------------------------------\n",
      "Average RMSE: 52.999110228891524, STD of RMSE: 5.718196604687865\n"
     ]
    }
   ],
   "source": [
    "model_blending.blending(model='xgboost', params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4dc85d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 0, RMSE: 48.32977629437627\n",
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 1, RMSE: 59.66372557855936\n",
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 2, RMSE: 56.444674065926876\n",
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 3, RMSE: 55.826507642063895\n",
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 4, RMSE: 48.95141089065684\n",
      "-----------------------------------------------------------------\n",
      "Average RMSE: 53.84321889431665, STD of RMSE: 4.447631643372908\n"
     ]
    }
   ],
   "source": [
    "model_blending.blending(model='lightgbm', params=lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "272eb06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.00777899281706"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_blending.predict(models=['xgboost', 'lightgbm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31d368",
   "metadata": {},
   "source": [
    "The model blending result is not much better than any single model since I only used two models with target encoding.\n",
    "You can combine different models with different encoding strategies even different features to improve the overall performance.\n",
    "\n",
    "For instance, you can combine XGBoost, LightGBM, and CatBoost with one-hot encoding, target encoding, ordinal encoding, and polynomial encoding. Then you have 3 X 4 models for model blending."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff2fc6",
   "metadata": {},
   "source": [
    "#### Model Stacking\n",
    "Reference: [Ensemble Learning: Stacking, Blending & Voting](https://towardsdatascience.com/ensemble-learning-stacking-blending-voting-b37737c4f483)\n",
    "Reference: [How To Use “Model Stacking” To Improve Machine Learning Predictions](https://medium.com/geekculture/how-to-use-model-stacking-to-improve-machine-learning-predictions-d113278612d4)\n",
    "\n",
    "Model Stacking is a way to improve model predictions by combining the outputs of multiple models and running them through another machine learning model called a meta-learner.\n",
    "\n",
    "After hyperparameter tuning, we have a set of beter hyperparameters for XGBoost and LightGBM. Then I performed a model blending for a better ML performance.\n",
    "\n",
    "My 200 Trails (200 × 5 in total) hyperparameters:\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "{'lambda': 0.029949323233957558, 'alpha': 0.47821306780284645, 'reg_lambda': 0.03007272817610808, 'reg_alpha': 5.7650942972599255e-05, 'colsample_bytree': 0.32733907049678806, 'subsample': 0.9397958925107069, 'learning_rate': 0.016087339011505105, 'n_estimators': 4117, 'max_depth': 6, 'random_state': 42, 'min_child_weight': 5}\n",
    "\n",
    "- LightGBM\n",
    "\n",
    "{'random_state': 42, 'num_iterations': 5549, 'learning_rate': 0.07313607774375752, 'max_depth': 5, 'num_leaves': 75, 'min_data_in_leaf': 100, 'lambda_l1': 1.3379869858112054e-06, 'lambda_l2': 0.00025091437242776726, 'feature_fraction': 0.5910800704597817, 'bagging_fraction': 0.9553891294481797, 'bagging_freq': 6, 'min_child_samples': 23}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "389b27a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Stacking:\n",
    "    def __init__(self, data_frame, features_etl, features_ml):\n",
    "        data_frame = data_frame.copy()\n",
    "        self.ml_pipeline = ML_pipeline(data_frame=data_frame, features=features_etl, target='price')\n",
    "        self.features_ml = features_ml\n",
    "    \n",
    "    def _xgboost_reg(self, xgb_params):\n",
    "        \"\"\"\n",
    "        # For GPU\n",
    "        model = XGBRegressor(\n",
    "                    tree_method='gpu_hist',\n",
    "                    gpu_id=0,\n",
    "                    predictor='gpu_predictor',\n",
    "                    n_jobs=-1,\n",
    "                    **xgb_params\n",
    "                )\n",
    "        \"\"\"\n",
    "        \n",
    "        # For CPU\n",
    "        model = XGBRegressor(**xgb_params)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _lightgbm_reg(self, lgb_params):\n",
    "        \"\"\"\n",
    "        # For GPU\n",
    "        model = LGBMRegressor(\n",
    "                    device='gpu',\n",
    "                    gpu_platform_id=0,\n",
    "                    gpu_device_id=0,\n",
    "                    n_jobs=-1,\n",
    "                    metric='rmse',\n",
    "                    **lgb_params\n",
    "                )\n",
    "        \"\"\"\n",
    "        \n",
    "        # For CPUT\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def stacking(self, model: str, params: dict):\n",
    "        '''Model blending. Generate 5 predictions according to 5 folds.\n",
    "        \n",
    "        Args:\n",
    "            model: One of xgboost or lightgbm.\n",
    "            params: Hyperparameters for XGBoost or LightGBM.\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        assert model in ['xgboost', 'lightgbm'], \"ValueError: model must be one of ['xgboost', 'lightgbm']!\"\n",
    "        \n",
    "        final_valid_predictions = {}\n",
    "        scores = []\n",
    "        \n",
    "        for fold in range(5):\n",
    "            X_train, X_valid, y_train, y_valid = self.ml_pipeline.getData(kfold=fold, target_encoding=True)\n",
    "            X_train, X_valid = X_train[self.features_ml], X_valid[self.features_ml] # Add many amenities\n",
    "            # Get X_valid_ids\n",
    "            X_valid_ids = list(X_valid.index)\n",
    "            \n",
    "            print(f\"Training ...\")\n",
    "            # Define model\n",
    "            if model == 'xgboost':\n",
    "                reg = self._xgboost_reg(params)\n",
    "            elif model == 'lightgbm':\n",
    "                reg = self._lightgbm_reg(params)\n",
    "\n",
    "            # Modeling - Training\n",
    "            reg.fit(\n",
    "                X_train, y_train, \n",
    "                early_stopping_rounds=300,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # Modeling - Inference\n",
    "            valid_preds = reg.predict(X_valid)\n",
    "            \n",
    "            final_valid_predictions.update(dict(zip(X_valid_ids, valid_preds))) # loop 5 times with different valid id\n",
    "\n",
    "            rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "            scores.append(rmse)\n",
    "            print(f'Fold: {fold}, RMSE: {rmse}')\n",
    "            \n",
    "        # Export results\n",
    "        if not os.path.exists('output'):\n",
    "            os.mkdir('output')\n",
    "        final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "        final_valid_predictions.columns = [\"id\", f\"{model}_pred\"]\n",
    "        final_valid_predictions.to_csv(f\"output/{model}_valid_pred.csv\", index=False)\n",
    "\n",
    "        print('-----------------------------------------------------------------')\n",
    "        print(f'Average RMSE: {np.mean(scores)}, STD of RMSE: {np.std(scores)}')\n",
    "        \n",
    "    def predict(self, models: list):\n",
    "        df_valids = pd.read_csv(f'output/{models[0]}_valid_pred.csv')\n",
    "        models.remove(models[0])\n",
    "        for model in models:\n",
    "            df = pd.read_csv(f'output/{model}_valid_pred.csv')\n",
    "            df_valids = df_valids.set_index('id').join(df.set_index('id'), how='inner')\n",
    "        \n",
    "        # Join listings price to df_valids\n",
    "        df_valids['price'] = listings.set_index('id')['price']\n",
    "        \n",
    "        # Implement a simple regressor such as linear regression\n",
    "        linear_reg = LinearRegression()\n",
    "        \n",
    "        # Define X, y\n",
    "        X, y = df_valids.iloc[:, :len(models)], df_valids.price\n",
    "        \n",
    "        # Use the models validations as training set for predictions\n",
    "        scores = cross_val_score(linear_reg, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        scores = -scores\n",
    "        return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4758779",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_etl = ['host_acceptance_rate', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "            'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "            'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "            'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate', 'host_is_superhost', \n",
    "            'accommodates', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', \n",
    "            'maximum_nights', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', \n",
    "            'require_guest_phone_verification', 'amenities', 'demand', 'kfold']\n",
    "\n",
    "features_ml = ml2\n",
    "\n",
    "xgb_params = {'lambda': 0.029949323233957558, 'alpha': 0.47821306780284645, 'reg_lambda': 0.03007272817610808, \n",
    "              'reg_alpha': 5.7650942972599255e-05, 'colsample_bytree': 0.32733907049678806, 'subsample': 0.9397958925107069, \n",
    "              'learning_rate': 0.016087339011505105, 'n_estimators': 4117, 'max_depth': 6, 'random_state': 42, 'min_child_weight': 5}\n",
    "\n",
    "lgb_params = {'random_state': 42, 'num_iterations': 5549, 'learning_rate': 0.07313607774375752, 'max_depth': 5, 'num_leaves': 75, \n",
    "             'min_data_in_leaf': 100, 'lambda_l1': 1.3379869858112054e-06, 'lambda_l2': 0.00025091437242776726, \n",
    "             'feature_fraction': 0.5910800704597817, 'bagging_fraction': 0.9553891294481797, 'bagging_freq': 6, 'min_child_samples': 23}\n",
    "\n",
    "model_stacking = Model_Stacking(listings, features_etl, features_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e9bd4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Fold: 0, RMSE: 47.754405543201784\n",
      "Training ...\n",
      "Fold: 1, RMSE: 61.119641697842376\n",
      "Training ...\n",
      "Fold: 2, RMSE: 54.63793671561086\n",
      "Training ...\n",
      "Fold: 3, RMSE: 56.08790855238088\n",
      "Training ...\n",
      "Fold: 4, RMSE: 45.39565863542171\n",
      "-----------------------------------------------------------------\n",
      "Average RMSE: 52.999110228891524, STD of RMSE: 5.718196604687865\n"
     ]
    }
   ],
   "source": [
    "model_stacking.stacking('xgboost', xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1018bcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 0, RMSE: 48.32977629437627\n",
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 1, RMSE: 59.66372557855936\n",
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 2, RMSE: 56.444674065926876\n",
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 3, RMSE: 55.826507642063895\n",
      "Training ...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5910800704597817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5910800704597817\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=23 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3379869858112054e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3379869858112054e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9553891294481797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9553891294481797\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00025091437242776726, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00025091437242776726\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Fold: 4, RMSE: 48.95141089065684\n",
      "-----------------------------------------------------------------\n",
      "Average RMSE: 53.84321889431665, STD of RMSE: 4.447631643372908\n"
     ]
    }
   ],
   "source": [
    "model_stacking.stacking('lightgbm', lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "071651e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.064662484075676"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stacking.predict(models=['xgboost', 'lightgbm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba8cc3",
   "metadata": {},
   "source": [
    "- The model stacking result is not much better than any single model since I only used two models with target encoding.\n",
    "You can combine different models with different encoding strategies even different features to improve the overall performance.\n",
    "\n",
    "- For instance, you can combine XGBoost, LightGBM, and CatBoost with one-hot encoding, target encoding, ordinal encoding, and polynomial encoding. Then you have  3×4 models for model stacking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
